# -*- coding: utf-8 -*-
"""Banking_Analytics_Credit_Card_Scoring.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1swcWZmxOKUCf7hUnZYe8kLf7WcJ8KnqO

***Credit card lending is one of the most common offerings in modern Fintechs. Usually granted by a 
bank, these products are now being granted by a Fintech that acts as a front for a bank that actually 
takes the risk. Deciding who to grant these services is an interesting problem under these 
circumstances.
In this coursework, you will develop a fully compliant PD model from the data they make available, 
from the raw data to the level 2 calibration, using what you have learned in the lectures. The 
objective of the coursework is to estimate the capital requirements for the credit card company as 
if they were a bank. 
You are given information from approximately 50,000 credit cards. The data includes information 
from the application to the credit card in Brazil during 2007, some of which can be used to predict 
the performance of the loan. The variable description is available in the Excel file 
“CC_VariablesList.xls”***
"""

from google.colab import drive
drive.mount("/content/drive", force_remount=True)

!pip install scorecardpy

!ls drive//MyDrive/CC_Modeling_Data.txt

"""**Data Import**"""

!ls drive/MyDrive/
import pandas as pd

filename = 'drive//MyDrive/CC_Modeling_Data.txt'

import pandas as pd
import chardet
with open(filename, 'rb') as f:
    result = chardet.detect(f.read())

result

df = pd.read_csv(filename, header=None, sep='\t', engine='python', encoding=result['encoding'])
df.head(2)

filename1 = 'drive//MyDrive/CC_VariablesList.XLS'
df1 = pd.read_excel(filename1, 0)
df1.head()

df.columns = df1['Var_Title']
df.rename({'TARGET_LABEL_BAD=1':'default'}, axis=1, inplace=True)

df.head()

"""**Identifying variables with single values**"""

mylist = []

for i in df.columns:
  if len(set(df[i])) ==1:
    print("The columns %s has only one value" %i)
    print(type(df.iloc[6][i]))
    a = set(df[i])
    print(a)
    if len(a)==1:
      mylist.append(i)

print(mylist)

from matplotlib import pyplot as plt
mylist.remove('EDUCATION_LEVEL')
mylist.remove('EDUCATION_LEVEL')

fig, axes = plt.subplots(1, len(mylist))

for ii, i in enumerate(mylist):
  axes[ii].hist(df[i])
plt.show()

"""**Removal of variables with single value**"""

list_to_remove = ['CLERK_TYPE', 'QUANT_ADDITIONAL_CARDS', 'FLAG_MOBILE_PHONE', 'FLAG_HOME_ADDRESS_DOCUMENT', 'FLAG_RG', 'FLAG_CPF', 'FLAG_INCOME_PROOF', 'FLAG_ACSP_RECORD']

for i in list_to_remove:
  if i in df.columns:
    df.drop([i], axis=1, inplace=True)

df.describe()

"""**Education Level is a duplicate variable**"""

import numpy as np

A = np.zeros(len(df['EDUCATION_LEVEL'])) 
B = np.zeros(len(df['EDUCATION_LEVEL'])) 
C = np.zeros(len(df['EDUCATION_LEVEL'])) 

for ii, i in enumerate(range(0, 50000)):
  
  new_list = []
  my_list = []
  my_list = df.iloc[ii]['EDUCATION_LEVEL']

  B[ii] = my_list[0]
  C[ii] = my_list[1]

  new_list = [item for item in my_list if not(np.isnan(item)) == True]
  if (len(new_list)>0):
    A[ii] = np.max(new_list)
  else:
    A[ii] = np.nan

A[A==0] = np.nan
df['education'] = A
df['education1'] = B
df['education2'] = C

df.drop(['EDUCATION_LEVEL'], axis=1, inplace=True)
df.drop(['education'], axis=1, inplace=True)
df.drop(['education1'], axis=1, inplace=True)

"""**Here I removed variables related to the identity of an applicant or variables which do not contribute to the creditworthiness of an applicant**"""

cols_to_remove = ['ID_CLIENT', 'FLAG_EMAIL', 'APPLICATION_SUBMISSION_TYPE', 'SEX', 'STATE_OF_BIRTH', 'CITY_OF_BIRTH','NACIONALITY']
for i in cols_to_remove:
  if i in df.columns:
    df.drop([i], axis=1, inplace=True)

null_columns = df.columns[df.isnull().any()]
df[null_columns].isnull().sum()

df['dummy_profession'] = df['PROFESSIONAL_CITY']
df.loc[df['dummy_profession'].isnull()==False, 'dummy_profession'] = 1
df.loc[df['dummy_profession'].isnull(), 'dummy_profession'] = 0

"""**Identifying Invalid Outliers**"""

df['MARITAL_STATUS'] = df['MARITAL_STATUS'].replace({0: np.nan})

my_list2 = ['MONTHS_IN_RESIDENCE']



for i in my_list2:
  print("For the columns %s " %(i))
  print("The number of nans is %f" %len((df.loc[df[i].isnull(), i])))

  df.loc[df[i].isnull(), i] = 0

df.describe()

null_columns = df.columns[df.isnull().any()]
df[null_columns].isnull().sum()

for i in df.columns:

  b = df.loc[df[i] == 0, i]
  if len(b)>0:
    print(" Columns %s ----%f" %(i, len(b)))

df['RESIDENCIAL_PHONE_AREA_CODE_new'] = df['RESIDENCIAL_PHONE_AREA_CODE']
df.loc[(df['FLAG_RESIDENCIAL_PHONE']=='N') & (df['RESIDENCIAL_PHONE_AREA_CODE_new']==' '),'RESIDENCIAL_PHONE_AREA_CODE_new'] = -1
df.loc[(df['FLAG_RESIDENCIAL_PHONE']=='Y') & (df['RESIDENCIAL_PHONE_AREA_CODE_new']==' '),'RESIDENCIAL_PHONE_AREA_CODE_new'] = np.nan

df['PROFESSIONAL_PHONE_AREA_CODE_new'] = df['PROFESSIONAL_PHONE_AREA_CODE']
df.loc[(df['FLAG_PROFESSIONAL_PHONE']=='N') & (df['PROFESSIONAL_PHONE_AREA_CODE_new']==' '),'PROFESSIONAL_PHONE_AREA_CODE_new'] = -1
df.loc[(df['FLAG_PROFESSIONAL_PHONE']=='Y') & (df['PROFESSIONAL_PHONE_AREA_CODE_new']==' '),'PROFESSIONAL_PHONE_AREA_CODE_new'] = np.nan

df.loc[(df['PROFESSIONAL_CITY'].isnull()) & (df['PROFESSIONAL_ZIP_3']== '#DIV/0!')]
df.loc[df['PROFESSIONAL_ZIP_3']== '#DIV/0!', 'PROFESSIONAL_ZIP_3'] = np.nan
df.loc[df['RESIDENCIAL_ZIP_3']== '#DIV/0!', 'RESIDENCIAL_ZIP_3'] = np.nan

df.loc[df['PROFESSIONAL_STATE']== ' ', 'PROFESSIONAL_STATE'] = np.nan

df.loc[df['RESIDENCIAL_BOROUGH']== ' ', 'RESIDENCIAL_BOROUGH'] = np.nan

mylist = ['PROFESSIONAL_PHONE_AREA_CODE', 'RESIDENCIAL_PHONE_AREA_CODE']
for i in mylist:
  df.drop([i], axis=1, inplace=True)

"""**Remove Columns with more than 50% Nans**"""

Threshold = 0.5
mylist = []
for ii in df.columns:
  t = df[ii].isnull().sum()/len(df)
  if t> Threshold:
    mylist.append(ii)
    print(' The columns is %s %f' %(ii,t))

print(mylist)
for i in mylist:
  df.drop([i], axis=1, inplace=True)

"""**Remove rows if more than 70% of data is null - No records were found**


"""

threshold = 0.7
for ii in range(0, len(df)):

  t = df.iloc[ii].isnull().sum()
  if t > len(df.columns) * threshold:
    print(ii)

"""**Outlier removal ** ****"""

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
# %matplotlib inline

sns.set(color_codes=True)
df3 = df.select_dtypes(include=np.number)
print(len(df3.columns))
for col_id in df3.columns:
  sns.displot(data = df3, x = df3[col_id], hue = "default", kind = 'kde')

"""**Creating New Variables**"""

C = df['FLAG_VISA'].values + df['FLAG_MASTERCARD'].values + df['FLAG_DINERS'].values + df['FLAG_AMERICAN_EXPRESS'].values + df['FLAG_OTHER_CARDS'].values

df['Total_cards'] = C

D = (df['PERSONAL_MONTHLY_INCOME'].values + df['OTHER_INCOMES'].values)/(1+ df['QUANT_DEPENDANTS'].values)

E = df['OTHER_INCOMES'].values + df['QUANT_DEPENDANTS'].values

df['Income_per_person'] = D

df['Total_Income'] = E

fig, (ax1, ax2, ax3) = plt.subplots(1, 3)

ax1.hist(df['Total_cards'])
ax1.set_title('Total_cards')
ax2.hist(df['Income_per_person'])
ax2.set_title('Income_per_person')
ax3.hist(df['Total_Income'])
ax3.set_title('Total_Income')

# # fig = sns.displot(df['Total_cards'], kind = 'hist')
# print(np.max(C))
plt.show()

"""**Valid Outlier Removal**"""

from matplotlib import pyplot as plt

fig, axes = plt.subplots(1, 2)
axes[0].hist(df['PERSONAL_MONTHLY_INCOME'])
df = df[df['PERSONAL_MONTHLY_INCOME']<4000]
axes[1].hist(df['PERSONAL_MONTHLY_INCOME'])
plt.title('PERSONAL_MONTHLY_INCOME')
plt.show()

fig, axes = plt.subplots(1, 2)
axes[0].hist(df['MONTHS_IN_RESIDENCE'])
df = df[df['MONTHS_IN_RESIDENCE']< 50]
axes[1].hist(df['MONTHS_IN_RESIDENCE'])
plt.title('MONTHS_IN_RESIDENCE')

plt.show()

# print(df.loc[df['AGE']< 18, 'AGE'])
fig, axes = plt.subplots(1, 2)
axes[0].hist(df['AGE'])
df.loc[df['AGE']< 18, 'AGE'] = np.nan
df.loc[df['AGE']> 80, 'AGE'] = np.nan
axes[1].hist(df['AGE'])
plt.title('AGE')

plt.show()

df['OTHER_INCOMES_dummy'] =  df['OTHER_INCOMES']
df.loc[df['OTHER_INCOMES_dummy']>0, 'OTHER_INCOMES_dummy'] = 1

df['PERSONAL_ASSETS_VALUE_dummy'] =  df['PERSONAL_ASSETS_VALUE']
df.loc[df['PERSONAL_ASSETS_VALUE_dummy']>0, 'PERSONAL_ASSETS_VALUE_dummy'] = 1

from matplotlib import pyplot as plt

fig, axes = plt.subplots(1, 2)
axes[0].hist(df['QUANT_DEPENDANTS'])
df.loc[df['QUANT_DEPENDANTS']>15, 'QUANT_DEPENDANTS'] = np.nan
axes[1].hist(df['QUANT_DEPENDANTS'])
plt.title('QUANT_DEPENDANTS')

plt.show()

"""***Replace Null Values***"""

df.isnull().any()

mylist = ['MARITAL_STATUS', 'OCCUPATION_TYPE', 'PROFESSION_CODE', 'RESIDENCE_TYPE', 'education2', 'RESIDENCIAL_ZIP_3', 'PROFESSIONAL_ZIP_3', 'RESIDENCIAL_PHONE_AREA_CODE_new', 
          'PROFESSIONAL_PHONE_AREA_CODE_new', 'RESIDENCIAL_BOROUGH']


for i in mylist:
  if i in df.columns:
    repl = df.loc[:,i].mode()
    print(repl[0])
    df[i].fillna(value = repl[0], inplace=True)


mylist = ['MONTHS_IN_RESIDENCE', 'AGE', 'QUANT_DEPENDANTS']

for i in mylist:
  if i in df.columns:  
    repl = df.loc[:,i].median(skipna=True)
    print(repl)
    if i == 'QUANT_DEPENDANTS':
      df[i].fillna(value = np.floor(repl), inplace=True)
    else:
      df[i].fillna(value = repl, inplace=True)

df.isnull().any()

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
# %matplotlib inline

df.to_csv('drive//MyDrive/df_assignment2.csv', index=False)

"""**Logistic Regression and Weight of Evidence**"""

import pandas as pd
# df = pd.read_csv('drive//MyDrive/df_assignment2.csv')
list_to_remove = ['RESIDENCIAL_CITY', 'RESIDENCIAL_BOROUGH', 'PROFESSIONAL_BOROUGH', 'PROFESSIONAL_CITY']

for i in list_to_remove:
  if i in df.columns:
    df.drop([i], axis=1, inplace=True)

list_to_remove = ['FLAG_AMERICAN_EXPRESS', 'FLAG_DINERS', 'POSTAL_ADDRESS_TYPE', 'PERSONAL_ASSETS_VALUE_dummy', 'MONTHS_IN_THE_JOB', 'FLAG_OTHER_CARDS', 'PERSONAL_ASSETS_VALUE']

for i in list_to_remove:
  if i in df.columns:
    df.drop([i], axis=1, inplace=True)

import scorecardpy as sc

train, test = sc.split_df(df,
                          y = 'default',
                          ratio = 0.7,
                          seed = 250542531).values()

train.to_csv('drive/MyDrive/train.csv', index=None)
test.to_csv('drive/MyDrive/test.csv', index=None)

train.iloc[:, ~train.columns.isin(['default'])]

import numpy as np


bins = sc.woebin(train, y= 'default', 
                 min_perc_fine_bin=0.01, # How many bins to cut initially into
                 min_perc_coarse_bin=0.05,  # Minimum percentage per final bin
                 stop_limit=0.005, # Minimum information value 
                 max_num_bin=6, # Maximum number of bins
                 method='tree'
                 )

import pickle

pickle.dump(bins, open("drive/MyDrive/bins.pkl", "wb"))  # save it into a file named bin.pkl

sc.woebin_plot(bins)

breaks_adj = sc.woebin_adj(train, "default", bins, adj_all_var = True)

pickle.dump(breaks_adj, open("drive/MyDrive/breaks_adj.pkl", "wb"))  # save it into a file named bin.pkl

bins_adj = sc.woebin(train, y="default", breaks_list=breaks_adj) # Apply new cuts
train_woe = sc.woebin_ply(train, bins_adj) # Calculate WoE dataset (train)
test_woe = sc.woebin_ply(test, bins_adj) # Calculate WoE dataset (test)
df_woe = sc.woebin_ply(df, bins_adj)

IV = sc.iv(train_woe, 'default')
IV

th = 0.01
mylist = ['default']
for ii, i in enumerate(IV['variable']):
  if IV.iloc[ii]['info_value'] > th:
    mylist.append(i)

print(mylist)

import json
json_acceptable_string = breaks_adj.replace("'", "\"")
breaks_adj_dict = json.loads(json_acceptable_string)

breaks_adj_store = dict()
for i in mylist:
  if i!='default':
    j = i.split('_woe')[0]
    breaks_adj_store[j] = breaks_adj_dict[j]

breaks_adj_store

import pickle

breaks_adj_reduced ={'AGE': [23.0, 33.0, 45.0, 53.0, 58.0],
 'FLAG_RESIDENCIAL_PHONE': ['Y', 'N'],
 'MARITAL_STATUS': [2.0, 3.0, 5.0],
 'OCCUPATION_TYPE': [1.0, 2.0, 4.0, 5.0],
 'PAYMENT_DAY': [15.0, 20.0, 25.0],
 'PROFESSIONAL_ZIP_3': [400.0, 620.0, 660.0, 840.0, 950.0],
 'RESIDENCIAL_PHONE_AREA_CODE_new': [0.0, 41.0, 63.0, 84.0, 91.0],
 'RESIDENCIAL_STATE': ['SC%,%RO%,%RS',
  'PR%,%MA%,%PB',
  'AP%,%MG%,%SP%,%MS%,%PA%,%MT%,%PI',
  'GO%,%RJ%,%CE',
  'RR%,%PE%,%ES%,%RN%,%BA%,%AC%,%TO',
  'AL%,%AM%,%DF%,%SE'],
 'RESIDENCIAL_ZIP_3': [400.0, 620.0, 660.0, 840.0, 950.0]}

pickle.dump(breaks_adj_reduced, open("drive/MyDrive/breaks_adj_reduced.pkl", "wb"))  # save it into a file named bin.pkl

train_woe_reduced = train_woe.iloc[:, train_woe.columns.isin(mylist)]
test_woe_reduced = test_woe.iloc[:, test_woe.columns.isin(mylist)]
df_woe_reduced = df_woe.iloc[:, df_woe.columns.isin(mylist)]

mylist1= []
for i in mylist:
  mylist1.append(i.split('_woe')[0])

# print(mylist1)

train_reduced = train.iloc[:, train.columns.isin(mylist1)]
test_reduced = test.iloc[:, test.columns.isin(mylist1)]
df_reduced = df.iloc[:, df.columns.isin(mylist1)]

train_woe_reduced.to_csv("drive/MyDrive/train_woe_reduced.csv", index = False)
test_woe_reduced.to_csv("drive/MyDrive/test_woe_reduced.csv", index = False)
df_woe_reduced.to_csv("drive/MyDrive/df_woe_reduced.csv", index = False)

train_woe.to_csv("drive/MyDrive/train_woe.csv", index = False)
test_woe.to_csv("drive/MyDrive/test_woe.csv", index = False)
df_woe.to_csv("drive/MyDrive/df_woe.csv", index = False)

train_reduced.to_csv("drive/MyDrive/train_reduced.csv", index = False)
test_reduced.to_csv("drive/MyDrive/test_reduced.csv", index = False)
df_reduced.to_csv("drive/MyDrive/df_reduced.csv", index = False)

# Commented out IPython magic to ensure Python compatibility.
from string import ascii_letters
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline

corr = train_woe_reduced.corr()
corr = np.abs(corr)
mask = np.triu(np.ones_like(corr, dtype=bool))
f, ax = plt.subplots(figsize=(11, 9))
cmap = sns.diverging_palette(230, 20, as_cmap=True)
sns.heatmap(corr, mask=mask, cmap=cmap, vmax=1, center=0,
            square=True, linewidths=.5, cbar_kws={"shrink": .5})

import pandas as pd
train_woe_reduced = pd.read_csv('drive/MyDrive/train_woe_reduced.csv')
test_woe_reduced = pd.read_csv('drive/MyDrive/test_woe_reduced.csv')
df_woe_reduced = pd.read_csv('drive/MyDrive/df_woe_reduced.csv')

train_woe_reduced.drop(['PROFESSIONAL_ZIP_3_woe'], axis=1, inplace=True)
test_woe_reduced.drop(['PROFESSIONAL_ZIP_3_woe'], axis = 1, inplace=True)
df_woe_reduced.drop(['PROFESSIONAL_ZIP_3_woe'], axis = 1, inplace=True)
# train_woe_reduced.columns

from sklearn.linear_model import LogisticRegressionCV, LogisticRegression
import numpy as np

l_r = LogisticRegressionCV(Cs=np.arange(0.1, 1, 0.1), cv=10, penalty='elasticnet', solver='saga', tol=1e-4, 
                           max_iter=1000, class_weight='balanced', n_jobs=2, refit=True, l1_ratios = np.arange(0.1, 1.0, 0.1),
                           random_state=250542531, verbose=2)

l_r.fit(X = train_woe_reduced.iloc[:, ~train_woe_reduced.columns.isin(['default'])], y= train_woe_reduced['default'])

li = train_woe_reduced.columns[~train_woe_reduced.columns.isin(['default'])]
pd.concat([pd.DataFrame(li, columns=['variable']), pd.DataFrame(np.transpose(l_r.coef_), columns=['Logistic_Regression_Coef'])], axis=1)



import pickle

pickle.dump(l_r, open('drive/MyDrive/Logitic_regression_model.pkl', 'wb'))

import pickle
l_r = pickle.load(open('drive/MyDrive/Logitic_regression_model.pkl', 'br'))

import numpy as np
from matplotlib import pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix, accuracy_score, f1_score
train_pred_lr = l_r.predict(train_woe_reduced.iloc[:, ~train_woe_reduced.columns.isin(['default'])].values)
train_pred_prob_lr = l_r.predict_proba(train_woe_reduced.iloc[:, ~train_woe_reduced.columns.isin(['default'])].values)


train_accuracy = accuracy_score(y_true = train_woe_reduced['default'], y_pred = train_pred_lr)
print("Accuracy of training dataset is: %f" %train_accuracy)


test_pred_lr = l_r.predict(test_woe_reduced.iloc[:, ~test_woe_reduced.columns.isin(['default'])])
test_pred_prob_lr = l_r.predict_proba(test_woe_reduced.iloc[:, ~test_woe_reduced.columns.isin(['default'])])


test_accuracy = accuracy_score(y_true = test_woe_reduced['default'], y_pred = test_pred_lr)
print("Accuracy of test dataset is: %f" %test_accuracy)




c = confusion_matrix(y_true = test_woe_reduced['default'], y_pred = test_pred_lr)
c = c.astype('float') / c.sum(axis=1)[:, np.newaxis]

confusion_matrix_l_r = pd.DataFrame(c, columns=['good', 'bad'], index=['good', 'bad'])
confusion_matrix_l_r

figsize = (10,7)
fontsize=16

# Create image
fig = plt.figure(figsize=figsize)
heatmap = sns.heatmap(confusion_matrix_l_r, annot=True, fmt='.2f')

heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, 
                             ha='right', fontsize=fontsize)
heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45,
                             ha='right', fontsize=fontsize)

# Add labels
plt.ylabel('True label')
plt.xlabel('Predicted label')

# Plot!
plt.show()

from matplotlib import pyplot as plt
plt.hist(train_pred_prob_lr[:,0], 50)
plt.show()

train_woe_reduced_lrprob = train_woe_reduced
test_woe_reduced_lrprob = test_woe_reduced

train_pred_prob_1 = [i[1] for i in train_pred_prob_lr]
test_pred_prob_1 = [i[1] for i in test_pred_prob_lr]

train_woe_reduced_lrprob['prob'] = train_pred_prob_1
test_woe_reduced_lrprob['prob'] = test_pred_prob_1

train_woe_reduced_lrprob.to_csv('drive/MyDrive/train_woe_reduced_lrprob.csv', index=None)
test_woe_reduced_lrprob.to_csv('drive/MyDrive/test_woe_reduced_lrprob.csv', index=None)

train_woe_reduced_lrprob = pd.read_csv('drive/MyDrive/train_woe_reduced_lrprob.csv')
test_woe_reduced_lrprob = pd.read_csv('drive/MyDrive/test_woe_reduced_lrprob.csv')

train_woe_reduced.columns

from sklearn.metrics import roc_curve, roc_auc_score
import matplotlib.pyplot as plt
lr_fp, lr_tp, lr_th = roc_curve(test_woe_reduced_lrprob['default'], test_woe_reduced_lrprob['prob'])

auc = np.round(roc_auc_score(y_true = test_woe_reduced_lrprob['default'], 
                             y_score = test_woe_reduced_lrprob['prob']),
               decimals = 3)

plt.plot(lr_fp,lr_tp,label="Scorecard, auc="+str(auc))
plt.legend(loc=4)
    
# Settings
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('1-Specificity(False Positive Rate)')
plt.ylabel('Sensitivity(True Positive Rate)')
plt.title('Receiver Operating Characteristic')
plt.legend(loc="lower right")
    
# Plot!    
plt.show()

"""**Designing a ScoreCard**"""

train_reduced = pd.read_csv('drive/MyDrive/train_reduced.csv')
train_reduced.drop(['PROFESSIONAL_ZIP_3'], axis=1, inplace=True)

import pickle
import scorecardpy as sc

out = open('drive/MyDrive/breaks_adj.pkl', 'rb')
breaks_adj = pickle.load(out)

out.close()

bins_adj = sc.woebin(train_reduced, y='default', breakpoint=breaks_adj)

out = open('drive/MyDrive/bins.pkl', 'rb')
bins = pickle.load(out)
out.close()
bins_adj

scoorecard = pickle.load(open('drive/MyDrive/scoorecard.pkl', 'rb'))

scoorecard['RESIDENCIAL_STATE']

scoorecard['RESIDENCIAL_ZIP_3']

scoorecard['RESIDENCIAL_PHONE_AREA_CODE_new']

scoorecard['PAYMENT_DAY']

scoorecard['OCCUPATION_TYPE']

scoorecard['MARITAL_STATUS']

scoorecard['FLAG_RESIDENCIAL_PHONE']

scoorecard['AGE']

if 'prob' in train_woe_reduced.columns:
  train_woe_reduced.drop(['prob'], axis=1, inplace=True)
  
li = train_woe_reduced.columns[~train_woe_reduced.columns.isin(['default'])]

bins_adj_reduced = dict()

for i in li:
  i = i.split('_woe')[0]
  # A = bins_adj[i]['breaks'].values
  print(i)
  bins_adj_reduced[i] = bins_adj[i]
  # print(i)
  # print(bins_adj[i])

print(bins_adj_reduced.keys())

df_sc = sc.scorecard(bins_adj_reduced,         # bins from the WoE
                    l_r,  # Trained logistic regression
                    train_woe_reduced.columns[~train_woe_reduced.columns.isin(['default'])], # The column names in the trained LR
                    points0=700, # Base points
                    odds0=0.02, # Base odds bads:goods
                    pdo=50
                    ) # PDO 

pickle.dump(df_sc, open('drive/MyDrive/scoorecard.pkl', 'wb'))

train_reduced_1 = pd.read_csv('drive/MyDrive/train_reduced.csv')
test_reduced_1 = pd.read_csv('drive/MyDrive/test_reduced.csv')

train_score = sc.scorecard_ply(train_reduced_1, df_sc, 
                               print_step=0)
test_score = sc.scorecard_ply(test_reduced_1, df_sc, 
                               print_step=0)

train_score.to_csv('drive/MyDrive/train_score.csv', index=None)
test_score.to_csv('drive/MyDrive/test_score.csv', index=None)

test_score.describe()

"""**Designing a Two Point CutOff**"""

import pandas as pd
train_woe_reduced_lrprob = pd.read_csv('drive/MyDrive/train_woe_reduced_lrprob.csv')
test_woe_reduced_lrprob = pd.read_csv('drive/MyDrive/test_woe_reduced_lrprob.csv')
test = pd.read_csv('drive/MyDrive/test.csv')

m = [0.50, 0.55]

test_woe_reduced_lrprob['loan'] = test['PERSONAL_MONTHLY_INCOME']
test_score = pd.read_csv('drive/MyDrive/test_score.csv')

thresholds = np.arange(0.25, 0.8, 0.05)
# thresholds = np.arange(test_score['score'].min(), test_score['score'].max(), 20)

output = pd.DataFrame(index=thresholds, columns=['Accuracy_Good', 'Accuracy_Defaulters', 'Total_Accuracy', 'Avg_Cost', 'Avg_Revenue', 'Total_Cost', 'Total_Revenue', 'Net Income'])

n_default_total= test_woe_reduced_lrprob.loc[(test_woe_reduced_lrprob['default']==1), 'prob'].count()
n_goods_total= test_woe_reduced_lrprob.loc[(test_woe_reduced_lrprob['default']==0), 'prob'].count()

for ii, i in enumerate(output.index):

  
  n = test_woe_reduced_lrprob.loc[test_woe_reduced_lrprob['prob']<=i, 'prob'].count()

  n_default_reject = test_woe_reduced_lrprob.loc[(test_woe_reduced_lrprob['prob']>i) & (test_woe_reduced_lrprob['default']==1), 'prob'].count()
  n_goods_reject = test_woe_reduced_lrprob.loc[(test_woe_reduced_lrprob['prob']>i) & (test_woe_reduced_lrprob['default']==0), 'prob'].count()
  
  n_default= test_woe_reduced_lrprob.loc[(test_woe_reduced_lrprob['prob']<=i) & (test_woe_reduced_lrprob['default']==1), 'prob'].count()
  n_goods= test_woe_reduced_lrprob.loc[(test_woe_reduced_lrprob['prob']<=i) & (test_woe_reduced_lrprob['default']==0), 'prob'].count()



  output.iloc[ii]['Accuracy_Good'] = n_goods/n_goods_total
  output.iloc[ii]['Accuracy_Defaulters'] = n_default_reject/n_default_total
  output.iloc[ii]['Total_Accuracy'] = (n_goods + n_default_reject)/(n_default_total + n_goods_total)

  output.iloc[ii]['Total_Revenue'] = (0.2 * 0.32) * test_woe_reduced_lrprob.loc[(test_woe_reduced_lrprob['prob']<=i) & (test_woe_reduced_lrprob['default']==0), 'loan'].sum()
  output.iloc[ii]['Avg_Revenue'] = (0.2 * 0.32) * test_woe_reduced_lrprob.loc[(test_woe_reduced_lrprob['prob']<=i) & (test_woe_reduced_lrprob['default']==0), 'loan'].mean()


  output.iloc[ii]['Total_Cost'] = (0.32) * test_woe_reduced_lrprob.loc[(test_woe_reduced_lrprob['prob']<=i) & (test_woe_reduced_lrprob['default']==1), 'loan'].sum()
  output.iloc[ii]['Avg_Cost'] = (0.32) * test_woe_reduced_lrprob.loc[(test_woe_reduced_lrprob['prob']<=i) & (test_woe_reduced_lrprob['default']==1), 'loan'].mean()

  output.iloc[ii]['Net Income'] = output.iloc[ii]['Total_Revenue'] - output.iloc[ii]['Total_Cost']

out = test_woe_reduced_lrprob.loc[(test_woe_reduced_lrprob['prob']<=m[1]) & (test_woe_reduced_lrprob['prob']>m[0]), 'loan'].count()

print("Number of Applicants to be processed manually is: %d" %out)
output

import matplotlib.pyplot as plt


# fig, axes = plt.subplots(1,2)
plt.plot(thresholds, output['Accuracy_Good']) 
# plt.plot(thresholds, output['Accuracy_Defaulters']) 
plt.plot(thresholds, output['Total_Accuracy']) 
plt.plot([0.5, 0.5], [0, 1], '--r')
plt.plot([0.55, 0.55], [0, 1], '--r')
plt.legend(['Accuracy_Good', 'Total_Accuracy'])
plt.grid()
plt.show()

import matplotlib.pyplot as plt

# fig, axes = plt.subplots(1,2)
plt.plot(thresholds, output['Net Income']) 
plt.plot([0.5, 0.5], [output['Net Income'].min(),output['Net Income'].max()], '--r')
plt.plot([0.55, 0.55], [output['Net Income'].min(),output['Net Income'].max()], '--r')
plt.legend(['Net Income'])
plt.grid()
plt.show()

import matplotlib.pyplot as plt

# fig, axes = plt.subplots(1,2)
# plt.plot(thresholds, output['Net Income']) 
plt.plot(thresholds, output['Total_Revenue']) 
plt.plot(thresholds, output['Total_Cost']) 
plt.legend(['Total_Revenue', 'Total_Cost'])
plt.plot([0.5, 0.5], [output['Total_Cost'].min(),output['Total_Cost'].max()], '--r')
plt.plot([0.55, 0.55], [output['Total_Cost'].min(),output['Total_Cost'].max()], '--r')
plt.grid()
plt.show()

"""# **Random Forest**


"""

!ls drive/MyDrive/df_assignment2.csv

import pandas as pd
df = pd.read_csv('drive/MyDrive/df_assignment2.csv')
df

df['PROFESSION_CODE'] = df['PROFESSION_CODE'].astype('object')
df['OCCUPATION_TYPE'] = df['OCCUPATION_TYPE'].astype('object')
df['POSTAL_ADDRESS_TYPE'] = df['POSTAL_ADDRESS_TYPE'].astype('object')
df['PRODUCT'] = df['PRODUCT'].astype('object')

df['MARITAL_STATUS'] = df['MARITAL_STATUS'].astype('object')
df['RESIDENCE_TYPE'] = df['RESIDENCE_TYPE'].astype('object')
df['RESIDENCIAL_ZIP_3'] = df['RESIDENCIAL_ZIP_3'].astype('object')
df['PROFESSIONAL_ZIP_3'] = df['PROFESSIONAL_ZIP_3'].astype('object')
df['RESIDENCIAL_PHONE_AREA_CODE_new'] = df['RESIDENCIAL_PHONE_AREA_CODE_new'].astype('object')
df['PROFESSIONAL_PHONE_AREA_CODE_new'] = df['PROFESSIONAL_PHONE_AREA_CODE_new'].astype('object')

numeric_cols = df.select_dtypes(include=np.number).columns[~df.select_dtypes(include=np.number).columns.isin(['default'])]

from scipy.stats import zscore

df[numeric_cols] = df[numeric_cols].apply(zscore)

df.to_csv('drive/MyDrive/df_after_normalize.csv', index=False)

import pandas as pd
df = pd.read_csv('drive/MyDrive/df_after_normalize.csv')
li = ['RESIDENCIAL_CITY', 'RESIDENCIAL_BOROUGH']
for i in li:
  if i in df.columns:
    df.drop([i], axis=1, inplace=True)

import scorecardpy as sc
import numpy as np

df_woe = pd.read_csv('drive/MyDrive/df_woe.csv')

dummy_columns=['MARITAL_STATUS', 'RESIDENCIAL_STATE', 'RESIDENCE_TYPE', 'PROFESSION_CODE', 'OCCUPATION_TYPE', 'PRODUCT', 'RESIDENCIAL_ZIP_3', 'PROFESSIONAL_ZIP_3', 'RESIDENCIAL_PHONE_AREA_CODE_new','PROFESSIONAL_PHONE_AREA_CODE_new', 'FLAG_RESIDENCIAL_PHONE', 'COMPANY', 'FLAG_PROFESSIONAL_PHONE']

woe_columns=['RESIDENCIAL_STATE', 'RESIDENCIAL_ZIP_3', 'PROFESSIONAL_ZIP_3', 'RESIDENCIAL_PHONE_AREA_CODE_new','PROFESSIONAL_PHONE_AREA_CODE_new']


for i in woe_columns:
  df[i] = df_woe[i+'_woe'].values
  for jj, j in enumerate(df[i].unique()):
    df.loc[df[i]==j, i] = jj

df = pd.get_dummies(df, columns=dummy_columns, drop_first=True)


df['default'] = df['default'].astype('int')
# len(df.columns)

train, test = sc.split_df(df,
                          y = 'default',
                          ratio = 0.7,
                          seed = 250542531).values()

len(df.columns)

from sklearn.ensemble import RandomForestClassifier

#Define the classifier
r_f = RandomForestClassifier(n_estimators=10000, # Number of trees to train
                       criterion='entropy', # How to train the trees. Also supports gini.
                       max_depth=None, # Max depth of the trees. Not necessary to change.
                       min_samples_split=2, # Minimum samples to create a split.
                       min_samples_leaf=0.0001, # Minimum samples in a leaf. Accepts fractions for %. This is 0.1% of sample.
                       min_weight_fraction_leaf=0.0, # Same as above, but uses the class weights.
                       max_features='auto', # Maximum number of features per split (not tree!) by default is sqrt(vars)
                       max_leaf_nodes=None, # Maximum number of nodes.
                       min_impurity_decrease=0.0001, # Minimum impurity decrease. This is 10^-4.
                       bootstrap=True, # If sample with repetition. For large samples (>100.000) set to false.
                       oob_score=True,  # If report accuracy with non-selected cases.
                       n_jobs=2, # Parallel processing. Set to the number of cores you have. Watch your RAM!!
                       random_state=250542531, # Seed
                       verbose=1, # If to give info during training. Set to 0 for silent training.
                       warm_start=False, # If train over previously trained tree.
                       class_weight='balanced' # Balance the classes.
                                    )

r_f.fit(X = train.iloc[:, ~train.columns.isin(['default'])].values, y= train['default'].values)

import pickle

pickle.dump(r_f, open('drive/MyDrive/Random_Forest_model.pkl', 'wb'))

import pickle

r_f = pickle.load(open('drive/MyDrive/Random_Forest_model.pkl', 'br'))

train_pred_rf = r_f.predict(train.iloc[:, ~train.columns.isin(['default'])].values)
train_pred_prob_rf = r_f.predict_proba(train.iloc[:, ~train.columns.isin(['default'])].values)

test_pred_rf = r_f.predict(test.iloc[:, ~test.columns.isin(['default'])].values)
test_pred_prob_rf = r_f.predict_proba(test.iloc[:, ~test.columns.isin(['default'])].values)

from sklearn.metrics import accuracy_score, confusion_matrix
train_accuracy = accuracy_score(y_true = train['default'], y_pred = train_pred_rf)
print("Accuracy of train dataset is: %f" %train_accuracy)

from matplotlib import pyplot as plt
plt.hist(train_pred_prob_rf[:,0], 50)
plt.show()

test_accuracy = accuracy_score(y_true = test['default'], y_pred = test_pred_rf)
print("Accuracy of test dataset is: %f" %test_accuracy)


c = confusion_matrix(y_true = test['default'], y_pred = test_pred_rf)
c = c.astype('float') / c.sum(axis=1)[:, np.newaxis]

confusion_matrix_r_f = pd.DataFrame(c, columns=['good', 'bad'], index=['good', 'bad'])
confusion_matrix_r_f

figsize = (10,7)
fontsize=16

# Create image
fig = plt.figure(figsize=figsize)
heatmap = sns.heatmap(confusion_matrix_r_f, annot=True, fmt='.2f')

heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, 
                             ha='right', fontsize=fontsize)
heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45,
                             ha='right', fontsize=fontsize)

# Add labels
plt.ylabel('True label')
plt.xlabel('Predicted label')

# Plot!
plt.show()

"""**Aggregating the importance for the Dummy Variables**"""

df_temp = pd.read_csv('drive/MyDrive/df_after_normalize.csv')
li = ['RESIDENCIAL_CITY', 'RESIDENCIAL_BOROUGH']
for i in li:
  if i in df.columns:
    df_temp.drop([i], axis=1, inplace=True)

importances = r_f.feature_importances_

importance_aggregate = np.zeros(len(df_temp.columns[~df_temp.columns.isin(['default'])]))
Variable_name = []

# list1 = ['OTHER_INCOMES_dummy']
# for jj, j in enumerate(list1):
for jj, j in enumerate(df_temp.columns[~df_temp.columns.isin(['default'])]):

  agg = 0

  for ii, i in enumerate(df.columns[~df.columns.isin(['default'])]):

    if i in ['OTHER_INCOMES_dummy', 'PERSONAL_ASSETS_VALUE_dummy','OTHER_INCOMES_dummy', 'OTHER_INCOMES']:
      
      if i == j:
        # print(i)
        agg = importances[ii]
    else:
      if j not in ['OTHER_INCOMES_dummy', 'PERSONAL_ASSETS_VALUE_dummy','OTHER_INCOMES_dummy', 'OTHER_INCOMES']:
      
        m = min(len(i.split('_')), len(j.split('_')))
        res = 0
        for k in range(m):
          if j.split('_')[k] != i.split('_')[k]:
            res = 1
        if res == 0:

          agg = agg + importances[ii]
          # print(i)


    

  importance_aggregate[jj] =agg
  Variable_name.append(j)
      
importance_aggregate
# Plot variable importance

f, ax = plt.subplots(figsize=(3, 8))
plt.title("Variable Importance - Random Forest")
sns.set_color_codes("pastel")
indices = np.argsort(importance_aggregate)



sns.barplot(y=[Variable_name[i] for i in indices], 
            x=importance_aggregate[np.argsort(importance_aggregate)], 
            label="Total", color="b")
ax.set(ylabel="Variable",
       xlabel="Variable Importance (Entropy)")
sns.despine(left=True, bottom=True)

import pickle
pickle.dump(r_f, open('drive/MyDrive/Random_Forest_model.pkl', 'wb'))

"""**XGboost**"""

import pandas as pd
df = pd.read_csv('drive/MyDrive/df_after_normalize.csv')
df_woe = pd.read_csv('drive/MyDrive/df_woe.csv')
li = ['RESIDENCIAL_CITY', 'RESIDENCIAL_BOROUGH']
for i in li:
  if i in df.columns:
    df.drop([i], axis=1, inplace=True)
df

import scorecardpy as sc
import numpy as np
dummy_columns=['MARITAL_STATUS', 'RESIDENCIAL_STATE', 'RESIDENCE_TYPE', 'PROFESSION_CODE', 'OCCUPATION_TYPE', 'PRODUCT', 'RESIDENCIAL_ZIP_3', 'PROFESSIONAL_ZIP_3', 'RESIDENCIAL_PHONE_AREA_CODE_new','PROFESSIONAL_PHONE_AREA_CODE_new', 'FLAG_RESIDENCIAL_PHONE', 'COMPANY', 'FLAG_PROFESSIONAL_PHONE']

woe_columns=['RESIDENCIAL_STATE', 'RESIDENCIAL_ZIP_3', 'PROFESSIONAL_ZIP_3', 'RESIDENCIAL_PHONE_AREA_CODE_new','PROFESSIONAL_PHONE_AREA_CODE_new']


for i in woe_columns:
  df[i] = df_woe[i+'_woe'].values
  for jj, j in enumerate(df[i].unique()):
    df.loc[df[i]==j, i] = jj

df = pd.get_dummies(df, columns=dummy_columns, drop_first=True)


df['default'] = df['default'].astype('int')
# len(df.columns)

train, test = sc.split_df(df,
                          y = 'default',
                          ratio = 0.7,
                          seed = 250542531).values()

len(df.columns)

scale_pos_weight = len(train.loc[train['default']==0]) / len(train.loc[train['default']==1])

from xgboost import XGBClassifier 
#Define the classifier.
x_g = XGBClassifier(max_depth=2,                 # Depth of each tree
                            learning_rate=0.1,            # How much to shrink error in each subsequent training. Trade-off with no. estimators.
                            n_estimators=50,             # How many trees to use, the more the better, but decrease learning rate if many used.
                            verbosity=1,                  # If to show more errors or not.
                            objective='binary:logistic',  # Type of target variable.
                            booster='gbtree',             # What to boost. Trees in this case.
                            n_jobs=2,                    # Parallel jobs to run. Set your processor number.
                            gamma=0.001,                  # Minimum loss reduction required to make a further partition on a leaf node of the tree. (Controls growth!)
                            subsample=0.632,              # Subsample ratio. Can set lower
                            colsample_bytree=1,           # Subsample ratio of columns when constructing each tree.
                            colsample_bylevel=1,          # Subsample ratio of columns when constructing each level. 0.33 is similar to random forest.
                            colsample_bynode=1,           # Subsample ratio of columns when constructing each split.
                            reg_alpha=1,                  # Regularizer for first fit. alpha = 1, lambda = 0 is LASSO.
                            reg_lambda=0,                 # Regularizer for first fit.
                            scale_pos_weight=scale_pos_weight,           # Balancing of positive and negative weights. G / B
                            base_score=0.5,               # Global bias. Set to average of the target rate.
                            random_state=250542531,        # Seed
                            missing=None,                 # How are nulls encoded?
                            tree_method='hist',       # How to train the trees?
                            # gpu_id=0                      # With which GPU? 
                            )

import numpy as np
# Define the parameters. Play with this grid!
param_grid = dict({'n_estimators': np.arange(100, 1000, 200),
                   'max_depth': [2, 3, 4],
                 'learning_rate' : np.arange(0.1, 0.3, 0.05)
                  })

# Always a good idea to tune on a reduce sample of the train set, as we will call many functions.
val_train = train.sample(frac = 0.2,               # The fraction to extract
                        random_state = 250542531,    # The seed.
                          )

from sklearn.model_selection import GridSearchCV

# Define grid search object.
GridXGB = GridSearchCV(x_g,                 # Original XGB. 
                       param_grid,          # Parameter grid
                       cv = 3,              # Number of cross-validation folds.  
                       scoring = 'roc_auc', # How to rank outputs.
                       n_jobs = 2,          # Parallel jobs. -1 is "all you have"
                       refit = False,       # If refit at the end with the best. We'll do it manually.
                       verbose = 1          # If to show what it is doing.
                      )

GridXGB.fit(val_train.iloc[:, ~val_train.columns.isin(['default'])], val_train['default'])

print('The best AUC is %.3f' % GridXGB.best_score_)
GridXGB.best_params_

x_g = XGBClassifier(max_depth=GridXGB.best_params_.get('max_depth'), # Depth of each tree
                            learning_rate=GridXGB.best_params_.get('learning_rate'), # How much to shrink error in each subsequent training. Trade-off with no. estimators.
                            n_estimators=GridXGB.best_params_.get('n_estimators'), # How many trees to use, the more the better, but decrease learning rate if many used.
                            verbosity=1,                  # If to show more errors or not.
                            objective='binary:logistic',  # Type of target variable.
                            booster='gbtree',             # What to boost. Trees in this case.
                            #n_jobs=4,                     # Parallel jobs to run. Set your processor number.
                            gamma=0.001,                  # Minimum loss reduction required to make a further partition on a leaf node of the tree. (Controls growth!)
                            subsample=0.632,              # Subsample ratio. Can set lower
                            colsample_bytree=1,           # Subsample ratio of columns when constructing each tree.
                            colsample_bylevel=1,          # Subsample ratio of columns when constructing each level. 0.33 is similar to random forest.
                            colsample_bynode=1,           # Subsample ratio of columns when constructing each split.
                            reg_alpha=1,                  # Regularizer for first fit. alpha = 1, lambda = 0 is LASSO.
                            reg_lambda=0,                 # Regularizer for first fit.
                            scale_pos_weight=scale_pos_weight,           # Balancing of positive and negative weights.
                            base_score=0.5,               # Global bias. Set to average of the target rate.
                            random_state=250542531,        # Seed
                            missing=None,                 # How are nulls encoded?
                            # tree_method='gpu_hist',       # How to train the trees?
                            gpu_id=0                      # With which GPU?
                            )

x_g.fit(X = train.iloc[:, ~train.columns.isin(['default'])].values, y= train['default'].values)

train_pred_xg = x_g.predict(train.iloc[:, ~train.columns.isin(['default'])].values)
train_pred_prob_xg = x_g.predict_proba(train.iloc[:, ~train.columns.isin(['default'])].values)

test_pred_xg = x_g.predict(test.iloc[:, ~test.columns.isin(['default'])].values)
test_pred_prob_xg = x_g.predict_proba(test.iloc[:, ~test.columns.isin(['default'])].values)

from matplotlib import pyplot as plt
plt.hist(train_pred_prob_xg[:,0], 50)
plt.show()

from sklearn.metrics import accuracy_score, confusion_matrix
train_accuracy = accuracy_score(y_true = train['default'], y_pred = train_pred_xg)
print("Accuracy of train dataset is: %f" %train_accuracy)

import matplotlib.pyplot as plt
import seaborn as sns
test_accuracy = accuracy_score(y_true = test['default'], y_pred = test_pred_xg)
print("Accuracy of test dataset is: %f" %test_accuracy)


c = confusion_matrix(y_true = test['default'], y_pred = test_pred_xg)
c = c.astype('float') / c.sum(axis=1)[:, np.newaxis]

confusion_matrix_r_f = pd.DataFrame(c, columns=['good', 'bad'], index=['good', 'bad'])
confusion_matrix_r_f

figsize = (10,7)
fontsize=16

# Create image
fig = plt.figure(figsize=figsize)
heatmap = sns.heatmap(confusion_matrix_r_f, annot=True, fmt='.2f')

heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, 
                             ha='right', fontsize=fontsize)
heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45,
                             ha='right', fontsize=fontsize)

# Add labels
plt.ylabel('True label')
plt.xlabel('Predicted label')

# Plot!
plt.show()

df_temp = pd.read_csv('drive/MyDrive/df_after_normalize.csv')
li = ['RESIDENCIAL_CITY', 'RESIDENCIAL_BOROUGH']
for i in li:
  if i in df.columns:
    df_temp.drop([i], axis=1, inplace=True)

importances = x_g.feature_importances_

importance_aggregate = np.zeros(len(df_temp.columns[~df_temp.columns.isin(['default'])]))
Variable_name = []

# list1 = ['OTHER_INCOMES_dummy']
# for jj, j in enumerate(list1):
for jj, j in enumerate(df_temp.columns[~df_temp.columns.isin(['default'])]):

  agg = 0

  for ii, i in enumerate(df.columns[~df.columns.isin(['default'])]):

    if i in ['OTHER_INCOMES_dummy', 'PERSONAL_ASSETS_VALUE_dummy','OTHER_INCOMES_dummy', 'OTHER_INCOMES']:
      
      if i == j:
        # print(i)
        agg = importances[ii]
    else:
      if j not in ['OTHER_INCOMES_dummy', 'PERSONAL_ASSETS_VALUE_dummy','OTHER_INCOMES_dummy', 'OTHER_INCOMES']:
      
        m = min(len(i.split('_')), len(j.split('_')))
        res = 0
        for k in range(m):
          if j.split('_')[k] != i.split('_')[k]:
            res = 1
        if res == 0:

          agg = agg + importances[ii]
          # print(i)


    

  importance_aggregate[jj] =agg
  Variable_name.append(j)
      
importance_aggregate
# Plot variable importance

f, ax = plt.subplots(figsize=(3, 8))
plt.title("Variable Importance - XG Boosting")
sns.set_color_codes("pastel")
indices = np.argsort(importance_aggregate)



sns.barplot(y=[Variable_name[i] for i in indices], 
            x=importance_aggregate[indices], 
            label="Total", color="b")
ax.set(ylabel="Variable",
       xlabel="Variable Importance (Entropy)")
sns.despine(left=True, bottom=True)

from sklearn.metrics import roc_auc_score,roc_curve
# Set models and probabilities. This structure is called a dictionary.
models = [
{
    'label': 'Logistic Regression',
    'probs': test_pred_prob_lr[:,1]
},
{
    'label': 'Gradient Boosting',
    'probs': test_pred_prob_xg[:,1]
},
{
    'label': 'Random Forest',
    'probs': test_pred_prob_rf[:,1]
}
]

# Loop that creates the plot. I will pass each ROC curve one by one.
for m in models:
  auc = roc_auc_score(y_true = test['default'], 
                             y_score = m['probs'])
  fpr, tpr, thresholds = roc_curve(test['default'], 
                                           m['probs'])
  plt.plot(fpr, tpr, label='%s ROC (area = %0.3f)' % (m['label'], auc))
                 

    
# Settings
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('1-Specificity(False Positive Rate)')
plt.ylabel('Sensitivity(True Positive Rate)')
plt.title('Receiver Operating Characteristic')
plt.legend(loc="lower right")
    
# Plot!    
plt.show()